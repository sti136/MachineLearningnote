## Linear Regression
Notation 
>
- m = Number of training examples
>
- x = input variable
>
- y = output variable
>
- (x,y) => one training example
>
- (x^i , j^i) -> ith training example
>
Training Set -> Learning Algoithm->hypothesis
>
x(input)->hypothesis->y(prediction)
>
example of symbol:

h(x) = c + mx
>
Cost Function
>
![Cost function](https://pic.pimg.tw/r101086616/1552488386-4264283465.png)
>
note: 1/2 in the cost function is to make convenience of the gradient desent method, Cost function is the difference between the predicted output and the real output.